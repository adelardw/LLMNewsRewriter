from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import START, END, StateGraph
from loguru import logger
import asyncio
from datetime import datetime
from src.config import OPEN_ROUTER_API_KEY, TEXT_IMAGE_MODEL, TEXT_GENERATION_MODEL, FINALIZER_LLM


from src.agents.prompts import (rewiritter_prompt, relevance_prompt, image_selection_prompt,theme_prompt,
                                image_description_prompt, meme_find_prompt,final_prompt, filter_prompt)

from src.agents.agent_schemas import SourceAgentGraph
from src.agents.utils import preproc_text_on_banned_org, measure_time_async
from src.tools.google_web_search import get_ddgs_image_loads
from src.tools.utils import rm_img_folders
from src.open_router import OpenRouterChat
from src.agents.structured_outputs import ImageSelection, FilterOutput

logger.add("logger_result.log", format="{time} {level} {message}", level="INFO")

llm = OpenRouterChat(api_key=OPEN_ROUTER_API_KEY,
                     model_name=TEXT_GENERATION_MODEL)

text_image_llm = OpenRouterChat(api_key=OPEN_ROUTER_API_KEY,
                               model_name=TEXT_IMAGE_MODEL)

finalizer_llm = OpenRouterChat(api_key=OPEN_ROUTER_API_KEY,
                               model_name=FINALIZER_LLM)


filter_agent = filter_prompt | llm.with_structured_output(FilterOutput)

news_classifier_agent = relevance_prompt | llm | StrOutputParser()
rewriter_agent = rewiritter_prompt | llm | StrOutputParser()
search_query_gen_agent = theme_prompt | llm.bind(max_tokens=40) | StrOutputParser()

image_selection_agent = image_selection_prompt | text_image_llm.with_structured_output(ImageSelection)
image_description_agent = image_description_prompt | text_image_llm | StrOutputParser()

meme_agent = meme_find_prompt | text_image_llm | StrOutputParser()

final = final_prompt | finalizer_llm | StrOutputParser()


'''@measure_time_async
async def prefilter_node(state):
    is_not_shit = await filter_agent.ainvoke({"post": state['post']})
    state['good_news'] = is_not_shit.good_news
    logger.info(f'[FILTERRESULT TAG] | Good News: {is_not_shit}')
    return state

@measure_time_async
async def prefilter_router(state):
    if state['good_news']:
        return "ğŸ‘€â‰ï¸ClassifierReactionNode"
    else:
        return END'''
    
@measure_time_async
async def classifier_node(state):
    post = state['post']
    emoji_reactions = state['emoji_reactions']
    if emoji_reactions:
        state['grade'] = await news_classifier_agent.ainvoke({'post': post,
                                                             'emoji_reactions':emoji_reactions})
    return state


@measure_time_async
async def media_ctx_router(state):
    if state.get('media_links', []):
        return "ğŸ¤¡ğŸ˜‚MemeNode"
    else:
        return "ğŸ“„âœï¸RewriterNode"


@measure_time_async
async def meme_node(state):
    media_links = state.get('media_links', [])
    post = state['post']
    emoji_reactions = state.get('emoji_reactions', {})
    
    try:
        
        generation = await meme_agent.ainvoke({'image_url': media_links,
                                                'post':post,
                                                'reactions': f'Ğ ĞµĞ°ĞºÑ†Ğ¸Ğ¸ Ñ Ğ¿Ğ¾ÑÑ‚Ğ°: {emoji_reactions}'})

        state['is_meme'] = is_meme = 'true' in generation.lower()
        if is_meme:
            state['generation'] = None
            
    except Exception as e:
        logger.info(f'Ğ¡Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ°ÑÑŒ ĞºĞ°ĞºĞ°Ñ - Ñ‚Ğ¾ Ğ¿Ñ€Ğ¸ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğ¸ Ğ¼ĞµĞ¼Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ÑÑ‚Ğ°: {e}')
        state['is_meme'] = False
    
    return state

@measure_time_async
async def meme_router(state):
    if not state['is_meme']:
        return "âœˆï¸ğŸ–¼ï¸MediaCtxNode"
    else:
        return END

@measure_time_async
async def media_ctx_node(state):

    if media_links:=state.get('media_links', []):
        try:
            image_description = await image_description_agent.ainvoke({'image_url': media_links})
            return {**state, 'media_ctx': image_description}
        
        except Exception as e:
            logger.info(f'Ğ¡Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ°ÑÑŒ ĞºĞ°ĞºĞ°Ñ - Ñ‚Ğ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¸ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸ Ğº Ğ¿Ğ¾ÑÑ‚Ñƒ {e}')
    
    return state


@measure_time_async
async def rewriter_node(state):
    post = state['post']
    grade = state.get('grade', None)
    media_ctx = state.get('media_ctx', None)
    
    if grade or media_ctx:
        addititional_info = "\n Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğº Ğ¿Ğ¾ÑÑ‚Ñƒ: \n"\
        
        addititional_info +=  f"ĞĞ³Ğ³Ñ€ĞµĞ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ¾Ñ‚ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°: \n {grade} \n" if grade else ''
        addititional_info += f"ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğº Ğ¿Ğ¾ÑÑ‚Ñƒ (Ğ¢ĞĞ›Ğ¬ĞšĞ ĞšĞĞš ĞšĞĞĞ¢Ğ•ĞšĞ¡Ğ¢): \n {media_ctx} \n" if media_ctx else ''
                       
        post += addititional_info

    
    state['generation'] = await rewriter_agent.ainvoke({'post': post})


    return state

@measure_time_async
async def postfilter_node(state):
    is_not_shit = await filter_agent.ainvoke({"post": state['generation']})
    state['good_news'] = is_not_shit.good_news
    state['generation'] = state['generation'] if state['good_news'] else None
    logger.info(f'[GOODGEN TAG] | {state["good_news"]}')
    return state

@measure_time_async
async def postfilter_router(state):
    if state['good_news']:
        return "ğŸ‘€ğŸ•¸ï¸ğŸŒMakeSearchQuery"
    else:
        return END

@measure_time_async
async def select_search_query_node(state):
    
    gen_post = state['generation']
    media_ctx = state.get('media_ctx', '')
    date = datetime.now()
    
    month = date.month
    year = date.year
    
    state['search_query']  = await search_query_gen_agent.ainvoke({'post': gen_post,
                                                                   'date': f'\n CĞµĞ¹Ñ‡Ğ°Ñ: {month} Ğ¼ĞµÑÑÑ† Ğ¸ {year} Ğ³Ğ¾Ğ´',
                                                                   'media_ctx': media_ctx})
    
    
    return state

@measure_time_async
async def select_image_to_post_node(state):
 
    search_query = state['search_query']
    generated_post = state['generation']
    
    finded_links = await asyncio.to_thread(get_ddgs_image_loads, query=search_query, max_images=5)
    rm_img_folders()

    if finded_links:        
        try:
            link_ind = await image_selection_agent.ainvoke({'query': "ĞšĞ°ĞºĞ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ / Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ / ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ° Ğ»ÑƒÑ‡ÑˆĞµ Ğ²ÑĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¿Ğ¾Ğ´ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¿Ğ¾ÑÑ‚? \n "\
                                                                    f"Ğ¢ĞµĞºÑÑ‚ Ğ¿Ğ¾ÑÑ‚Ğ°: \n {generated_post} \n" \
                                                                    f"ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ²ÑĞµĞ³Ğ¾: {len(finded_links)} Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹",

                                                            'image_url': finded_links})
            link_ind = int(link_ind.image_number)
            
            if link_ind != -1:
                url = finded_links.pop(link_ind)
                return {**state, 'image_url': url}
            else:   
                return {**state, 'image_url': None}

        except Exception as e:
            logger.info(f'Ğ¡Ğ»ÑƒÑ‡Ğ¸Ğ»Ğ°ÑÑŒ ĞºĞ°ĞºĞ°Ñ - Ñ‚Ğ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğµ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸ Ğº Ğ¿Ğ¾ÑÑ‚Ñƒ {e}')
    
    return {**state, 'image_url': None}

@measure_time_async
async def finalizer(state):
    text = preproc_text_on_banned_org(state['generation'])
    generation = await final.ainvoke({"post": text})
    validation = await filter_agent.ainvoke({"post": generation})
    state['generation'] = generation if validation.good_news else None
    logger.critical(f"[FINALGENERATED TAG] | {state['generation']}")
    return state

    
workflow = StateGraph(SourceAgentGraph)
#workflow.add_node('ğŸ“„â‰ï¸PreFilterNode', prefilter_node)
workflow.add_node('ğŸ‘€â‰ï¸ClassifierReactionNode', classifier_node)
workflow.add_node('ğŸ¤¡ğŸ˜‚MemeNode', meme_node)
workflow.add_node('âœˆï¸ğŸ–¼ï¸MediaCtxNode', media_ctx_node)
workflow.add_node('ğŸ“„âœï¸RewriterNode', rewriter_node)
workflow.add_node('âœï¸â‰ï¸PostFilterNode', postfilter_node)
workflow.add_node("ğŸ‘€ğŸ•¸ï¸ğŸŒMakeSearchQuery", select_search_query_node)
workflow.add_node('ğŸ‘€ğŸ–¼ï¸SelectImage4Post', select_image_to_post_node)
workflow.add_node('â‰ï¸Finalizer', finalizer)


# workflow.add_edge(START, 'ğŸ“„â‰ï¸PreFilterNode')
# workflow.add_conditional_edges('ğŸ“„â‰ï¸PreFilterNode',
#                                prefilter_router,
#                                {"ğŸ‘€â‰ï¸ClassifierReactionNode":"ğŸ‘€â‰ï¸ClassifierReactionNode",
#                                 END:END})

workflow.add_edge(START, 'ğŸ‘€â‰ï¸ClassifierReactionNode')
workflow.add_conditional_edges('ğŸ‘€â‰ï¸ClassifierReactionNode',
                               media_ctx_router,
                               {"ğŸ¤¡ğŸ˜‚MemeNode":"ğŸ¤¡ğŸ˜‚MemeNode",
                                "ğŸ“„âœï¸RewriterNode":"ğŸ“„âœï¸RewriterNode"})

workflow.add_conditional_edges('ğŸ¤¡ğŸ˜‚MemeNode',
                               meme_router,
                               {"âœˆï¸ğŸ–¼ï¸MediaCtxNode": "âœˆï¸ğŸ–¼ï¸MediaCtxNode",
                                END: END})

workflow.add_edge("âœˆï¸ğŸ–¼ï¸MediaCtxNode","ğŸ“„âœï¸RewriterNode")
#workflow.add_edge("ğŸ“„âœï¸RewriterNode", "ğŸ‘€ğŸ•¸ï¸ğŸŒMakeSearchQuery")
workflow.add_edge("ğŸ“„âœï¸RewriterNode", "âœï¸â‰ï¸PostFilterNode")

workflow.add_conditional_edges('âœï¸â‰ï¸PostFilterNode',
                               postfilter_router,
                               {"ğŸ‘€ğŸ•¸ï¸ğŸŒMakeSearchQuery":"ğŸ‘€ğŸ•¸ï¸ğŸŒMakeSearchQuery",
                                END:END})

workflow.add_edge("ğŸ‘€ğŸ•¸ï¸ğŸŒMakeSearchQuery", "ğŸ‘€ğŸ–¼ï¸SelectImage4Post")
workflow.add_edge("ğŸ‘€ğŸ–¼ï¸SelectImage4Post", "â‰ï¸Finalizer")
workflow.add_edge("â‰ï¸Finalizer", END)

async_graph = workflow.compile(debug=False)
